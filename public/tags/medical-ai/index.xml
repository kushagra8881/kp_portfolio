<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Medical AI on Kushagra Parashar | ML Engineer</title>
    <link>//localhost:1313/tags/medical-ai/</link>
    <description>Recent content in Medical AI on Kushagra Parashar | ML Engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 08 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1313/tags/medical-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Interpretable Deep Learning for GI Endoscopic Image Classification</title>
      <link>//localhost:1313/research/gi-endoscopic-classification/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/research/gi-endoscopic-classification/</guid>
      <description>ðŸ“š Publication Biomedical Physics &amp;amp; Engineering Express (IOP Publishing)&#xA;Overview This research focuses on making deep learning models interpretable for medical diagnosis, specifically for gastrointestinal (GI) endoscopic image classification.&#xA;ðŸ”¬ Research Contributions Interpretable AI for Healthcare Applied EfficientNet architecture for multi-class GI diagnosis Integrated Grad-CAM for visual explanations of model decisions Implemented LIME (Local Interpretable Model-agnostic Explanations) Achieved transparent multi-class diagnosis Key Innovations Combined state-of-the-art accuracy with interpretability Enabled clinicians to understand model reasoning Validated on real-world endoscopic image datasets ðŸŽ¯ Impact This work bridges the gap between high-performing deep learning models and clinical adoption by providing transparent, interpretable diagnoses that healthcare professionals can trust and verify.</description>
    </item>
    <item>
      <title>Data Augmentation for Breast Cancer Imaging using WGANs</title>
      <link>//localhost:1313/research/wgan-breast-cancer/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/research/wgan-breast-cancer/</guid>
      <description>ðŸ”¬ Ongoing Research Overview This research explores the use of Wasserstein GANs (WGANs) to generate synthetic medical images for breast cancer detection, addressing the critical challenge of limited medical imaging datasets.&#xA;ðŸŽ¯ Research Goals Data Augmentation Apply Wasserstein GANs with label smoothing Generate high-quality synthetic medical images Triple limited datasets for improved model training Improved Detection Enhance robustness of cancer detection models Address class imbalance in medical datasets Improve generalization across diverse patient populations ðŸ”§ Methodology WGAN Architecture Generator network for realistic image synthesis Critic network for quality assessment Wasserstein distance for stable training Label Smoothing Regularization technique for improved generation Better gradient flow during training More realistic synthetic samples ðŸ“Š Expected Outcomes Metric Target Dataset Size 3x increase Model Robustness Significant improvement Generalization Improved cross-domain performance Status ðŸ”„ Ongoing Research</description>
    </item>
    <item>
      <title>Data Augmentation for Breast Cancer Imaging using GANs</title>
      <link>//localhost:1313/posts/breast-cancer-gan/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/breast-cancer-gan/</guid>
      <description>Status: Ongoing Research&#xA;ðŸ“„ Abstract The limited availability of annotated medical imaging data remains a critical barrier in developing robust deep learning models, particularly in breast Ultrasound (US). This study presents a novel conditional Generative Adversarial Network (GAN) framework tailored for synthesizing high-quality breast US images in data-constrained environments.&#xA;ðŸ”¬ Methodology Our method is evaluated on 100 US images (one of the smallest publicly available breast US datasets) from the Open Access Series of Breast US Dataset (OASBUD), simulating real-world clinical scarcity.</description>
    </item>
    <item>
      <title>Interpretable Deep Learning for GI Endoscopic Images</title>
      <link>//localhost:1313/posts/gi-endoscopy/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/gi-endoscopy/</guid>
      <description>ðŸ“„ Abstract Gastrointestinal (GI) endoscopy serves as a vital tool for assessing the GI tract and diagnosing related disorders. Recent progress in deep learning has shown significant improvements in identifying anomalies using sophisticated models and data augmentation strategies.&#xA;This study introduces an enhanced approach to improve classification accuracy using 8,000 labeled endoscopic images from the Kvasir dataset, categorized into eight distinct classes. Leveraging EfficientNetB3 as the backbone, our proposed architecture eliminates the reliance on data augmentation while maintaining moderate model complexity.</description>
    </item>
  </channel>
</rss>
